{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "a365ComputeOptions": null,
    "sessionKeepAliveTimeout": 0,
    "trident": {
      "lakehouse": {
        "default_lakehouse": "{BRONZE_LAKEHOUSE_ID}",
        "default_lakehouse_name": "{BRONZE_LAKEHOUSE_NAME}",
        "default_lakehouse_workspace_id": "{WORKSPACE_ID}",
        "known_lakehouses": [
          {
            "id": "{BRONZE_LAKEHOUSE_ID}"
          }
        ]
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
      },
      "source": [
        "# copy CSV files to lakehouse to load data into bronze layer \n",
        "import requests\n",
        "\n",
        "csv_base_url = \"https://github.com/PowerBiDevCamp/ProductSalesData/raw/main/\"\n",
        "\n",
        "csv_files = { \"Customers.csv\", \"Products.csv\", \"Invoices.csv\", \"InvoiceDetails.csv\" }\n",
        "\n",
        "folder_path = \"Files/\"\n",
        "\n",
        "for csv_file in csv_files:\n",
        "    csv_file_path = csv_base_url + csv_file\n",
        "    with requests.get(csv_file_path) as response:\n",
        "        csv_content = response.content.decode('utf-8-sig')\n",
        "        mssparkutils.fs.put(folder_path + csv_file, csv_content, True)\n",
        "        print(csv_file + \" copied to Lakehouse file in OneLake\")"
      ]
    }
  ]
}